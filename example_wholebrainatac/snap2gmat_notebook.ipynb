{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eran Mukamel, February 2021\n",
    "# \n",
    "# Add a gene-by-cell matrix (gmat) to a .snap file. This should be equivalent to:  \n",
    "#   snaptools snap-add-gmat\n",
    "#\n",
    "# Usage: snap2gmat <snap-file> <genes-file>\n",
    "#\n",
    "# Inputs:\n",
    "#  snap_file = path to .snap file\n",
    "#  genes_file = path to bed file of genes \n",
    "#\n",
    "# Output\n",
    "#  Saves a file <snap-file>.gmat.npz\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re,os,sys\n",
    "import h5py,time\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Creating gene-by-cell matrix (gmat) from snap file\n",
      "*** Processing CEMBA190214_11E.snap:\n",
      "1617139085.7276356 100000 1000000\n",
      "1000000/100000: t=233.878 s; estimated total time = 0.390 min\n",
      "Saved output file CEMBA190214_11E.gmat.npz \n"
     ]
    }
   ],
   "source": [
    "# snap_file = sys.argv[1]\n",
    "# genes_file = sys.argv[2]\n",
    "\n",
    "snap_file = \"CEMBA190214_11E.snap\"\n",
    "genes_file = \"Annotation/gencode.vM16.annotation_up10kb.bed\"\n",
    "# genes_file = \"Annotation/gencode.vM16.annotation_pc_genes.tsv\"\n",
    "\n",
    "print('*** Creating gene-by-cell matrix (gmat) from snap file')\n",
    "print('*** Processing %s:' % snap_file)\n",
    "\n",
    "# TODO: Filter out cells with < 1000 reads\n",
    "\n",
    "# My attempt at a faster implementation of snaptools snap-add-gmat\n",
    "def assign_genes(filename,\n",
    "                 genes,\n",
    "                 istart=None,\n",
    "                 istop=None,\n",
    "                 verbose=False):\n",
    "    from scipy.sparse import coo_matrix\n",
    "    t0=time.time()\n",
    "    with h5py.File(filename,'r') as file:\n",
    "        if istart is None:\n",
    "            istart=0\n",
    "        if istop is None:\n",
    "            istop=file['FM/fragStart'].shape[0]\n",
    "\n",
    "        # Assign every fragment to a gene. NOTE: This will assign every fragment to ONE gene, even if it overlaps multiple genes\n",
    "        fragChrom = file['FM/fragChrom'][istart:istop].astype(str)\n",
    "        fragStart = file['FM/fragStart'][istart:istop]\n",
    "        fragEnd = fragStart + file['FM/fragLen'][istart:istop]\n",
    "\n",
    "        # Figure out the barcode index for each fragment\n",
    "        bc_pos = file['FM/barcodePos'][:]-1\n",
    "        bc_pos = np.append(bc_pos,np.inf)\n",
    "        fragBC = np.digitize(istart+np.arange(len(fragChrom)), bc_pos)\n",
    "        nbc = file['FM/fragChrom'].shape[0]\n",
    "        # TEMPORARY: Create smaller dataset for testing    \n",
    "        nbc = min(nbc, 100000)\n",
    "    if verbose:\n",
    "        print('Loaded data; t=%3.3f s' % (time.time()-t0))\n",
    "    \n",
    "    t0=time.time()\n",
    "    fragGene = np.empty(len(fragEnd))\n",
    "    i,j = np.array([],dtype=int),np.array([],dtype=int)\n",
    "    chroms = genes['chr'].unique()\n",
    "    for chrom in chroms:\n",
    "        gu = genes[genes['chr']==chrom]\n",
    "        fu = fragChrom==chrom\n",
    "        if fu.any():\n",
    "            fstart = fragStart[fu]\n",
    "            fend = fragEnd[fu]\n",
    "            fgene = fragGene[fu]\n",
    "            fbc = fragBC[fu]\n",
    "            \n",
    "            for gi in range(gu.shape[0]):\n",
    "                overlap_barcodes = fbc[(fend>gu.iloc[gi]['start']) & (fstart<gu.iloc[gi]['end'])]\n",
    "                if len(overlap_barcodes)>0:\n",
    "                    i=np.append(i,[gu.index[gi]]*len(overlap_barcodes))\n",
    "                    j=np.append(j,overlap_barcodes)\n",
    "        if verbose:\n",
    "            print('%s, %d genes, %d fragments, %d total overlaps, t=%3.3fs' % (chrom,gu.shape[0],fu.sum(),len(i),time.time()-t0))\n",
    "    ngenes = genes.shape[0]\n",
    "    gmat = coo_matrix((np.ones(len(i)), (i,j-1)), shape=(ngenes,nbc))\n",
    "    return gmat\n",
    "\n",
    "# 15 s for 10,000 fragments\n",
    "genes = pd.read_csv(genes_file,\n",
    "                    sep='\\t',\n",
    "                   header=None,\n",
    "                   names=['chr','start','end','ensid','gene','strand','type'])\n",
    "\n",
    "with h5py.File(snap_file,'r') as file:\n",
    "    nbc = file['FM/fragChrom'].shape[0]\n",
    "    # TEMPORARY: Create smaller dataset for testing    \n",
    "    nbc = min(nbc, 100000)\n",
    "\n",
    "chunksize = int(1e6)\n",
    "t0=time.time()\n",
    "\n",
    "print(t0, nbc, chunksize)\n",
    "ngenes = genes.shape[0]\n",
    "gmat = coo_matrix((ngenes,nbc), np.int)\n",
    "for istart in np.arange(0,nbc,chunksize):\n",
    "    gmat += assign_genes(snap_file,genes,istart=istart,istop=istart+chunksize)\n",
    "    tcurr = time.time()-t0\n",
    "    print('%d/%d: t=%3.3f s; estimated total time = %3.3f min' % (istart+chunksize,nbc,tcurr,\n",
    "                                                           tcurr*nbc/(istart+chunksize)/60))\n",
    "    \n",
    "    \n",
    "from scipy.sparse import save_npz\n",
    "save_npz(snap_file.replace('.snap','.gmat.npz'), gmat)\n",
    "print('Saved output file %s ' % snap_file.replace('.snap','.gmat.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select HVF from genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming to str index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"name\": shape (13257,), type \"|O\">\n",
      "(100000, 53379) 53379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming to str index.\n",
      "... storing 'chr' as categorical\n",
      "... storing 'gene' as categorical\n",
      "... storing 'strand' as categorical\n",
      "... storing 'type' as categorical\n"
     ]
    }
   ],
   "source": [
    "# Aditya: Save anndata\n",
    "import anndata as ad\n",
    "\n",
    "with h5py.File(snap_file,'r') as file:\n",
    "    print(file['BD']['name'])\n",
    "\n",
    "# TODO: Set obs to numerical index\n",
    "n_genes, n_obs = gmat.shape\n",
    "\n",
    "obs_df = pd.DataFrame(index=pd.RangeIndex(start=0, stop=n_obs))\n",
    "\n",
    "print(gmat.T.shape, len(genes))\n",
    "adata = ad.AnnData(X = gmat.T,\n",
    "                   obs = obs_df,\n",
    "                   var = genes,\n",
    "                   )\n",
    "\n",
    "results_file = snap_file.replace('.snap', '.gmat.h5ad')\n",
    "adata.write_h5ad(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"name\": shape (13257,), type \"|O\">\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
